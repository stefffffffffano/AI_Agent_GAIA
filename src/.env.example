#Max number of tokens that can be contained in the FIFO queue and in the working context->model specific
#The subdivision is inspired by MemGPT, these sizes are suggested for GPT-4o with a context window of 8192 tokens
MAX_FIFO_TOKENS = 6000
MAX_WORKING_CONTEXT_TOKENS = 1500 

#Model specification and key
MODEL= openai/gpt-4o
OPENAI_API_KEY= ...
